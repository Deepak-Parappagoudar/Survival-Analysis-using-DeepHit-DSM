{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63de781d",
   "metadata": {},
   "source": [
    "Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pycox "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f9ee01",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeeb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch \n",
    "import torchtuples as tt \n",
    "from pycox.models import CoxPH\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from pycox.evaluation import EvalSurv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3384f2",
   "metadata": {},
   "source": [
    "Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b7f417",
   "metadata": {
    "id": "f04avj6_ctcp"
   },
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "\n",
    "data = pd. read_csv('bpic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032530a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    " \n",
    "data.rename(columns={'Unnamed: 0': 'Case_ID', 'time:timestamp' : 'Complete Timestamp', 'concept:name': 'Activity', 'case:ApplicationType' : 'ApplicationType',  'case:LoanGoal': 'LoanGoal', 'case:RequestedAmount' : 'RequestedAmount', 'org:resource': 'user' }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080feb59",
   "metadata": {
    "id": "sLrUPX_gSNeZ"
   },
   "outputs": [],
   "source": [
    "# Format for DeepSurv. lable=1 => event happens, label=0=> event doesn't happen. \n",
    "\n",
    "data.loc[:, 'label'] = 1\n",
    "data.drop(columns=['EventID', 'OfferID','Case_ID' ],inplace=True)       # Drop columns that are useless.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ea798",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "_Rmn7IxIcqxe",
    "outputId": "2c6f5eab-c9f8-4a7f-85ea-e7f7ef9661e3"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899c8d6",
   "metadata": {
    "id": "13_NrHzraGSZ"
   },
   "outputs": [],
   "source": [
    "# Sort the data by \"application_id\" and \"timestamp\" in increasing order\n",
    "\n",
    "data = data.sort_values(by=[\"case:concept:name\", \"Complete Timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfab559",
   "metadata": {
    "id": "bui06mooaGPy"
   },
   "outputs": [],
   "source": [
    "# Re-arrange dataframe\n",
    "\n",
    "temp_col = data['case:concept:name']\n",
    "\n",
    "\n",
    "data.drop(columns=['case:concept:name'], inplace=True)\n",
    "\n",
    "\n",
    "data.insert(1, 'case:concept:name', temp_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049e6be",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33a07b",
   "metadata": {
    "id": "WJ8btcC5G-gT"
   },
   "outputs": [],
   "source": [
    "# Create a new fetaure 'duration'\n",
    "\n",
    "\n",
    "data['Complete Timestamp']=pd.to_datetime(data['Complete Timestamp'])\n",
    "\n",
    "grouped_df = data.groupby('case:concept:name')\n",
    "\n",
    "\n",
    "# Add a new column with the timestamp of the previous row\n",
    "data['prev_timestamp'] = grouped_df['Complete Timestamp'].shift(1)\n",
    "\n",
    "# Calculate the duration by subtracting the previous timestamp from the current timestamp\n",
    "data['duration'] = data['Complete Timestamp'] - data['prev_timestamp']\n",
    "\n",
    "data['duration']=data['duration'].dt.total_seconds()\n",
    "\n",
    "\n",
    "# Drop the temporary column\n",
    "data.drop(columns=['prev_timestamp'], inplace=True)\n",
    "\n",
    "data['duration']=data['duration'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca8fc0",
   "metadata": {
    "id": "Y4NJ3O7u_BOw"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cat_feats = ['Action','Activity', 'EventOrigin', 'lifecycle:transition', 'LoanGoal', 'ApplicationType', 'Accepted', 'Selected']           # categorical_features\n",
    "num_feats = ['RequestedAmount', 'FirstWithdrawalAmount', 'NumberOfTerms', 'MonthlyCost', 'CreditScore', 'OfferedAmount', 'duration']      # numerical_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4896c",
   "metadata": {
    "id": "Kq8sCa2m_EUj"
   },
   "outputs": [],
   "source": [
    "#Fill missing values with 0\n",
    "\n",
    "null_counts = data.isnull().sum()\n",
    "null_columns = null_counts[null_counts > 0].index\n",
    "\n",
    "for i in null_columns:\n",
    "  if i in num_feats:\n",
    "    data[i].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5d554",
   "metadata": {
    "id": "pSNQk9iwZAGO"
   },
   "outputs": [],
   "source": [
    "# Enocde the features to numerical representations \n",
    "\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "one_hot_features = one_hot_encoder.fit_transform(data[cat_feats])\n",
    "\n",
    "# The above line returns a sparse matrix, so we can convert it to a dense numpy array\n",
    "one_hot_features = one_hot_features.toarray()\n",
    "\n",
    "#  integer encode the cat_int_encoding feature remove this\n",
    "label_encoder = LabelEncoder()\n",
    "int_feature = label_encoder.fit_transform(data['case:concept:name'])\n",
    "\n",
    "# concatenate the one hot encoded features and the integer encoded feature, along with the numerical features\n",
    "final_features = np.concatenate((one_hot_features, int_feature.reshape(-1, 1)), axis=1)\n",
    "final_features = np.concatenate((one_hot_features, data[num_feats].values), axis=1)\n",
    "\n",
    "# final_features is now a numpy array that contains all of the encoded features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7179b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xs0QsDbQZADk",
    "outputId": "4677436d-bc5e-47bb-84c6-33da27687b21"
   },
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the array\n",
    "\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "# Next, let's add the one hot encoded features to the DataFrame\n",
    "one_hot_columns = []\n",
    "for i, col in enumerate(cat_feats):\n",
    "    one_hot_columns += [f\"{col}_{c}\" for c in one_hot_encoder.categories_[i]]\n",
    "df_final[one_hot_columns] = pd.DataFrame(one_hot_features)\n",
    "\n",
    "# Now, let's add the integer encoded feature to the DataFrame\n",
    "df_final['case:concept:name'] = int_feature\n",
    "\n",
    "# Finally, let's add the numerical features to the DataFrame\n",
    "df_final[num_feats] = data[num_feats]\n",
    "\n",
    "# Now, df_final is a DataFrame with the original column names and the encoded features\n",
    "\n",
    "# Reorder the columns to make 'case:concept:name' the first column\n",
    "df_final = df_final[['case:concept:name'] + one_hot_columns + num_feats]\n",
    "\n",
    "# The DataFrame now has 'case:concept:name' as the first column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9183545",
   "metadata": {
    "id": "mXodbC4O5Hv-"
   },
   "outputs": [],
   "source": [
    "# The Time duration, 'duration' is our target variable\n",
    "\n",
    "duration=df_final['duration'].values\n",
    "df_final.drop('duration', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8b9e2",
   "metadata": {
    "id": "kGGaoODjS9_j"
   },
   "outputs": [],
   "source": [
    "#This is how the DeepSurv format expects the data to be formatted.\n",
    "\n",
    "label=data['label']\n",
    "tar=np.column_stack((duration, label))\n",
    "df_target= pd.DataFrame(data=tar, columns=['duration', 'event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd826009",
   "metadata": {
    "id": "r3ZKIzsRANOk"
   },
   "outputs": [],
   "source": [
    "#Split the data into train,test and validation gropus\n",
    "\n",
    "x= df_final\n",
    "y=df_target\n",
    "grouped = x.groupby('case:concept:name')\n",
    "\n",
    "# Initialize empty lists to store the split datasets\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "x_val_list = []\n",
    "y_val_list = []\n",
    "x_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "# Iterate over the groups\n",
    "for user, group in grouped:\n",
    "  # Calculate the number of samples in each set\n",
    "  n = len(group)\n",
    "  tr_size = int(n * 0.60)  # 60% for training\n",
    "  vl_size = int(n * 0.20)  # 20% for validation\n",
    "  te_size = int(n * 0.20)  # 20% for test\n",
    "\n",
    "  # Split the group into training, validation, and test sets\n",
    "  x_train = group[:tr_size]\n",
    "  y_train = y[:tr_size]\n",
    "  x_val = group[tr_size:tr_size+vl_size]\n",
    "  y_val = y[tr_size:tr_size+vl_size]\n",
    "  x_test = group[-te_size:]\n",
    "  y_test = y[-te_size:]\n",
    "\n",
    "  # Append the split datasets to the list\n",
    "  x_train_list.append(x_train)\n",
    "  y_train_list.append(y_train)\n",
    "  x_val_list.append(x_val)\n",
    "  y_val_list.append(y_val)\n",
    "  x_test_list.append(x_test)\n",
    "  y_test_list.append(y_test)\n",
    "\n",
    "\n",
    "x_train = pd.concat(x_train_list)\n",
    "x_val = pd.concat(x_val_list)\n",
    "x_test = pd.concat(x_test_list)\n",
    "y_train = pd.concat(y_train_list)\n",
    "y_val = pd.concat(y_val_list)\n",
    "y_test = pd.concat(y_test_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eabd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disacrd the case:conept:name column, as it's not a feature, per se.\n",
    "\n",
    "\n",
    "x_train = x_train.iloc[:, 1:]\n",
    "x_test = x_test.iloc[:, 1:]\n",
    "x_val = x_val.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac754461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSurv requires arrays in 'float32'. \n",
    "\n",
    "x_train=x_train.values.astype('float32')\n",
    "x_val=x_val.values.astype('float32')\n",
    "x_test=x_test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655c5fb",
   "metadata": {},
   "source": [
    "Format the data as required by DeepSurv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acbfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
    "y_train = get_target(y_train)\n",
    "y_val = get_target(y_val)\n",
    "durations_test, events_test = get_target(y_test)\n",
    "y_test = get_target(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4411954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the duration arrays to float\n",
    "\n",
    "y_train = tuple(map(lambda x: x.astype('float32'), y_train))\n",
    "y_val = tuple(map(lambda x: x.astype('float32'), y_val))\n",
    "y_test = tuple(map(lambda x: x.astype('float32'), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af602a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = (x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d6d736",
   "metadata": {},
   "source": [
    "Configuration & Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model, initialize it & fit the data\n",
    "\n",
    "\n",
    "in_features = x_train.shape[1]\n",
    "num_nodes = [64, 64]\n",
    "out_features = 1\n",
    "batch_norm = True\n",
    "dropout = 0.2\n",
    "output_bias = False\n",
    "batch_size=64\n",
    "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.001, cycle_eta_multiplier=0.8,\n",
    "                            cycle_multiplier=2)\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm,\n",
    "                              dropout, output_bias=output_bias)\n",
    "                              \n",
    "model = CoxPH(net, optimizer) \n",
    "\n",
    "epochs = 100\n",
    "callbacks = [tt.callbacks.EarlyStopping()]\n",
    "verbose = True\n",
    "\n",
    "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
    "                val_data=val, val_batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da7ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Surviavl times \n",
    "\n",
    "\n",
    "_ = model.compute_baseline_hazards()\n",
    "surv = model.predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Survival function against time\n",
    "\n",
    "surv.iloc[:80, 50000].plot()\n",
    "plt.ylabel('S(t | x)')\n",
    "_ = plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d1104",
   "metadata": {},
   "source": [
    "Evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ca03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = EvalSurv(surv.iloc[:, :30000], durations_test[:30000], events_test[:30000], censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4582e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
